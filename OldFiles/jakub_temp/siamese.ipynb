{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from subprocess import check_output\n",
    "\n",
    "from my_classesnfunc import *\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, merge, Input, Lambda, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    SIZE = input_dim[0]\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(filters=15,\n",
    "                       kernel_size=(3, 3),\n",
    "                       activation='relu',\n",
    "                       input_shape = input_dim,\n",
    "                       padding = 'same'))\n",
    "    seq.add(MaxPooling2D())\n",
    "\n",
    "    seq.add(Conv2D(filters=30,\n",
    "                       kernel_size=(5, 5),\n",
    "                       activation='relu',\n",
    "                       padding = 'same'))\n",
    "    seq.add(MaxPooling2D())\n",
    "    seq.add(Flatten())\n",
    "        \n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(int((SIZE/4)**2), activation='relu'))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('tr_gr_64.h5', 'r')\n",
    "x = hf.get('x')\n",
    "y = hf.get('y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9040, 64, 64)\n",
      "(9040,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lohe = LabelOneHotEncoder()\n",
    "y_cat = lohe.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.shape(x)\n",
    "x = x.reshape((shape[0],shape[1],shape[2],1))\n",
    "input_dim = (shape[-3],shape[-2],shape[-1])\n",
    "SIZE = shape[2]\n",
    "n_el = shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype('float32')\n",
    "x /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_network = create_base_network(input_dim)\n",
    "\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "prediction = Dense(units=1,\n",
    "                       activation='sigmoid',\n",
    "                       )(distance)\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = x.reshape((n_el,SIZE**2))\n",
    "dists = np.zeros((n_el,n_el))\n",
    "for i in range(n_el):\n",
    "    for j in range(n_el):\n",
    "        if i >= j:\n",
    "            dists[i,j] = 0\n",
    "            continue\n",
    "        vec1 = x_flat[i]\n",
    "        vec2 = x_flat[j]\n",
    "        dists[i,j] = compute_distances_no_loops(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
